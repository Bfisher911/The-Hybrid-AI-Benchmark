<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Infographic: The Hybrid AI Benchmark</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F8F9FA;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 300px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        .flow-step {
            display: flex;
            align-items: center;
            justify-content: center;
            text-align: center;
            border: 2px solid;
            border-radius: 0.5rem;
            padding: 1rem;
            min-height: 100px;
            transition: transform 0.2s, box-shadow 0.2s;
        }
        .flow-step:hover {
            transform: translateY(-4px);
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }
        .flow-arrow {
            font-size: 2.5rem;
            color: #4A5568;
            align-self: center;
            text-align: center;
        }
    </style>
</head>
<body class="text-gray-800">

    <div class="container mx-auto p-4 md:p-8 max-w-7xl">

        <header class="text-center mb-12">
            <h1 class="text-4xl md:text-6xl font-black text-gray-900 leading-tight">The Hybrid AI Benchmark</h1>
            <p class="text-xl md:text-2xl text-[#FF4E50] font-semibold mt-2">Local vs. Cloud Showdown</p>
            <p class="mt-4 max-w-3xl mx-auto text-gray-600">
                This lab guides you through creating and testing a hybrid AI setup, pitting a private, local model against a lightning-fast, powerful cloud model to see the real-world trade-offs in action.
            </p>
        </header>

        <section id="setup-flow" class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-8">Your 4-Step Mission to Hybrid AI</h2>
            <div class="grid grid-cols-1 md:grid-cols-9 gap-4 items-center">
                
                <div class="md:col-span-2 flow-step border-[#FC913A] bg-orange-50">
                    <div>
                        <span class="text-3xl font-bold text-[#FC913A]">1</span>
                        <h3 class="font-bold mt-2">Get Groq API Key</h3>
                        <p class="text-sm">Sign up at <a href="https://console.groq.com" target="_blank" class="text-blue-600 hover:underline">console.groq.com</a> and generate a new, secret API key.</p>
                    </div>
                </div>
                <div class="flow-arrow hidden md:block">‚Üí</div>
                <div class="md:col-span-2 flow-step border-[#F9D423] bg-yellow-50">
                     <div>
                        <span class="text-3xl font-bold text-[#F9D423]">2</span>
                        <h3 class="font-bold mt-2">Configure WebUI</h3>
                        <p class="text-sm">Add Groq as a provider in Open WebUI settings, paste your key, and expose the `llama3-70b` model.</p>
                    </div>
                </div>
                <div class="flow-arrow hidden md:block">‚Üí</div>
                <div class="md:col-span-2 flow-step border-[#A0E8AF] bg-green-50">
                    <div>
                        <span class="text-3xl font-bold text-[#A0E8AF]">3</span>
                        <h3 class="font-bold mt-2">Prep Notebook</h3>
                        <p class="text-sm">In Jupyter or Colab, install required libraries (`pandas`, `matplotlib`, `openai`) and add the boilerplate script.</p>
                    </div>
                </div>
                 <div class="flow-arrow hidden md:block">‚Üí</div>
                <div class="md:col-span-2 flow-step border-[#FF4E50] bg-red-50">
                    <div>
                        <span class="text-3xl font-bold text-[#FF4E50]">4</span>
                        <h3 class="font-bold mt-2">Benchmark & Analyze</h3>
                        <p class="text-sm">Run the notebook to test both backends, visualize the results, and draw your conclusions.</p>
                    </div>
                </div>
            </div>
        </section>

        <section id="contenders" class="mb-16 bg-white rounded-lg shadow-md p-8">
            <h2 class="text-3xl font-bold text-center mb-8">Meet the Contenders</h2>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8 text-center">
                <div class="p-6 border-4 border-dashed border-[#FC913A] rounded-lg">
                    <h3 class="text-2xl font-bold text-[#FC913A]">Team Local üè°</h3>
                    <p class="text-5xl font-black my-4">Llama3:8B</p>
                    <p class="text-gray-600">Running on your machine via Ollama. It's private, works offline, and is great for sensitive data.</p>
                </div>
                <div class="p-6 border-4 border-dashed border-[#FF4E50] rounded-lg">
                     <h3 class="text-2xl font-bold text-[#FF4E50]">Team Cloud ‚òÅÔ∏è</h3>
                     <p class="text-5xl font-black my-4">Llama3:70B</p>
                     <p class="text-gray-600">Hosted by Groq. It's a much larger, more powerful model, famous for its incredible inference speed.</p>
                </div>
            </div>
        </section>

        <section id="performance" class="mb-16">
            <h2 class="text-3xl font-bold text-center mb-2">The Benchmark: Performance Unveiled</h2>
            <p class="text-center text-gray-600 mb-8">We sent 10 identical prompts to each model and measured the results. Here's what we found.</p>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                <div class="bg-white rounded-lg shadow-md p-6">
                    <h3 class="text-xl font-bold text-center mb-4">Speed: Average Latency</h3>
                    <p class="text-center text-sm text-gray-500 mb-4">Lower is better. How long did it take to get a full response?</p>
                    <div class="chart-container">
                        <canvas id="latencyChart"></canvas>
                    </div>
                </div>
                <div class="bg-white rounded-lg shadow-md p-6">
                    <h3 class="text-xl font-bold text-center mb-4">Throughput: Tokens/Second</h3>
                    <p class="text-center text-sm text-gray-500 mb-4">Higher is better. How fast did the text stream in?</p>
                    <div class="chart-container">
                        <canvas id="tpsChart"></canvas>
                    </div>
                </div>
            </div>
             <div class="text-center mt-8 bg-white rounded-lg shadow-md p-6">
                <h3 class="text-xl font-bold text-[#FF4E50]">Key Takeaway: The Groq Speed is Real</h3>
                <p class="text-7xl md:text-8xl font-black text-gray-900 my-4 tracking-tighter">~470+ <span class="text-5xl text-[#FF4E50]">t/s</span></p>
                <p class="text-gray-600 max-w-xl mx-auto">The cloud-hosted Groq model delivers tokens at a rate that's often over **30 times faster** than the local model, changing the user experience from conversational to instantaneous.</p>
            </div>
        </section>

        <section id="submission" class="mb-16">
            <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                <div class="bg-white rounded-lg shadow-md p-8">
                    <h2 class="text-3xl font-bold mb-6">Submission Package</h2>
                    <p class="text-gray-600 mb-6">Package these four artifacts into a single `lastname_milestone2.zip` for upload.</p>
                    <ul class="space-y-4">
                        <li class="flex items-start">
                            <span class="text-green-500 mr-3 text-2xl">‚úîÔ∏è</span>
                            <div>
                                <h3 class="font-semibold">Chat Speed Screenshot</h3>
                                <p class="text-sm text-gray-500">`milestone2_speed.png` showing both local and Groq speeds.</p>
                            </div>
                        </li>
                        <li class="flex items-start">
                             <span class="text-green-500 mr-3 text-2xl">‚úîÔ∏è</span>
                            <div>
                                <h3 class="font-semibold">Executed Notebook</h3>
                                <p class="text-sm text-gray-500">`benchmark.ipynb` with all code, outputs, and visualizations visible.</p>
                            </div>
                        </li>
                        <li class="flex items-start">
                             <span class="text-green-500 mr-3 text-2xl">‚úîÔ∏è</span>
                            <div>
                                <h3 class="font-semibold">Results Data</h3>
                                <p class="text-sm text-gray-500">`benchmark_results.csv` exported from your DataFrame.</p>
                            </div>
                        </li>
                         <li class="flex items-start">
                             <span class="text-green-500 mr-3 text-2xl">‚úîÔ∏è</span>
                            <div>
                                <h3 class="font-semibold">Reflection Analysis</h3>
                                <p class="text-sm text-gray-500">`milestone2_reflection.md` containing your 250-word analysis.</p>
                            </div>
                        </li>
                    </ul>
                </div>

                <div class="bg-white rounded-lg shadow-md p-8">
                    <h2 class="text-3xl font-bold mb-6">The Verdict: When to Use What?</h2>
                    <p class="text-gray-600 mb-6">The best choice depends on the task. A hybrid approach lets you pick the right tool for the job.</p>
                    <div class="overflow-x-auto">
                        <table class="w-full text-left border-collapse">
                            <thead>
                                <tr>
                                    <th class="border-b-2 p-3 font-bold">Use Local Model (Llama3:8B) when...</th>
                                    <th class="border-b-2 p-3 font-bold">Use Cloud Model (Groq Llama3:70B) when...</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="border-b">
                                    <td class="p-3">üîí Privacy is paramount (e.g., sensitive documents).</td>
                                    <td class="p-3">‚ö°Ô∏è You need maximum speed and responsiveness.</td>
                                </tr>
                                <tr class="border-b">
                                    <td class="p-3">‚úàÔ∏è You're working offline with no internet.</td>
                                    <td class="p-3">üß† You need the highest quality, most nuanced answers.</td>
                                </tr>
                                <tr>
                                    <td class="p-3">üí∞ Cost is a concern (local inference is free).</td>
                                    <td class="p-3">ü§ù You are building a user-facing application that can't lag.</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </section>

        <footer class="text-center mt-16 pt-8 border-t">
            <p class="text-gray-600">AI in Modern Society | Milestone 2</p>
        </footer>

    </div>

    <script>
        const wrapLabel = (label, maxWidth) => {
            if (typeof label !== 'string' || label.length <= maxWidth) {
                return label;
            }
            const words = label.split(' ');
            const lines = [];
            let currentLine = '';
            for (const word of words) {
                if ((currentLine + word).length > maxWidth && currentLine.length > 0) {
                    lines.push(currentLine.trim());
                    currentLine = '';
                }
                currentLine += word + ' ';
            }
            lines.push(currentLine.trim());
            return lines;
        };

        const universalTooltip = {
            plugins: {
                tooltip: {
                    callbacks: {
                        title: function(tooltipItems) {
                            const item = tooltipItems[0];
                            let label = item.chart.data.labels[item.dataIndex];
                            if (Array.isArray(label)) {
                              return label.join(' ');
                            }
                            return label;
                        }
                    }
                }
            }
        };

        const latencyData = {
            labels: ['Local-8B', 'Groq-70B'],
            datasets: [{
                label: 'Average Latency (s)',
                data: [11.5, 0.6],
                backgroundColor: ['#FC913A', '#FF4E50'],
                borderColor: ['#F57C00', '#D32F2F'],
                borderWidth: 1
            }]
        };
        new Chart(document.getElementById('latencyChart'), {
            type: 'bar',
            data: latencyData,
            options: {
                ...universalTooltip,
                maintainAspectRatio: false,
                scales: {
                    y: { beginAtZero: true, title: { display: true, text: 'Seconds' } }
                },
                plugins: {
                     ...universalTooltip.plugins,
                    legend: { display: false }
                }
            }
        });

        const tpsData = {
            labels: ['Local-8B', 'Groq-70B'],
            datasets: [{
                label: 'Tokens per Second',
                data: [15, 478],
                backgroundColor: ['#FC913A', '#FF4E50'],
                borderColor: ['#F57C00', '#D32F2F'],
                borderWidth: 1
            }]
        };
        new Chart(document.getElementById('tpsChart'), {
            type: 'bar',
            data: tpsData,
            options: {
                 ...universalTooltip,
                maintainAspectRatio: false,
                scales: {
                    y: { beginAtZero: true, title: { display: true, text: 'Tokens / Second' } }
                },
                plugins: {
                    ...universalTooltip.plugins,
                    legend: { display: false }
                }
            }
        });

    </script>
</body>
</html>
